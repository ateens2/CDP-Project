import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import os
import torch

# CPU ëª¨ë“œë¡œ ê°•ì œ ì„¤ì •
torch.set_num_threads(4)
os.environ['CUDA_VISIBLE_DEVICES'] = ''

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
current_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(current_dir, "ë”ë¯¸_ê³ ê°_ë°ì´í„°_í…ŒìŠ¤íŠ¸ì…‹.csv")

# ë”ë¯¸ ë°ì´í„° CSV ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(csv_path)
input_columns = df.columns.tolist()

# ë‚´ë¶€ í‘œì¤€ í•„ë“œ ì •ì˜ (ì˜ë¬¸ í•„ë“œ)
standard_fields = [
    "customer_id", "name", "email", "contact", "signup_date",
    "order_id", "order_date", "order_status", "total_price",
    "payment_method", "shipping_address",
    "product_id", "product_name", "product_category", "product_price", "quantity",
    "inquiry_id", "inquiry_type", "inquiry_create", "inquiry_finish", "inquiry_status"
]

# ê° ë‚´ë¶€ í•„ë“œì— ëŒ€ì‘í•˜ëŠ” í•œê¸€ ë¬¸ì¥í˜• ë¼ë²¨
standard_labels = [
    "ê³ ê° ê³ ìœ  ë²ˆí˜¸", "ê³ ê° ì´ë¦„", "ì´ë©”ì¼ ì£¼ì†Œ", "ì—°ë½ì²˜", "ê°€ì… ë‚ ì§œ",
    "ì£¼ë¬¸ ê³ ìœ  ë²ˆí˜¸", "ì£¼ë¬¸ ë‚ ì§œ", "ì£¼ë¬¸ ìƒíƒœ", "ì´ ê²°ì œ ê¸ˆì•¡",
    "ê²°ì œ ë°©ì‹", "ë°°ì†¡ì§€ ì£¼ì†Œ",
    "ìƒí’ˆ ê³ ìœ  ë²ˆí˜¸", "ìƒí’ˆ ì´ë¦„", "ìƒí’ˆ ì¹´í…Œê³ ë¦¬", "ìƒí’ˆ ê°€ê²©", "ìƒí’ˆ ìˆ˜ëŸ‰",
    "ë¬¸ì˜ ê³ ìœ  ë²ˆí˜¸", "ë¬¸ì˜ ìœ í˜•", "ë¬¸ì˜ ì ‘ìˆ˜ì¼", "ë¬¸ì˜ ì²˜ë¦¬ì¼", "ë¬¸ì˜ ì²˜ë¦¬ ìƒíƒœ"
]

# ë£° ê¸°ë°˜ ë§¤í•‘ ì‚¬ì „ (ê° ë‚´ë¶€ í‘œì¤€ í•„ë“œì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œ ëª©ë¡)
rule_based_mapping = {
    "name": ["ê³ ê°ëª…", "ì„±ëª…", "ì´ë¦„", "ì‚¬ìš©ìëª…", "íšŒì›ëª…"],
    "email": ["ì´ë©”ì¼", "E-mail", "email", "ë©”ì¼ì£¼ì†Œ", "ì´ë©”ì¼ ì£¼ì†Œ"],
    "contact": ["ì „í™”", "íœ´ëŒ€í°", "ì—°ë½ì²˜", "í•¸ë“œí°", "í°ë²ˆí˜¸", "ëª¨ë°”ì¼"],
    "signup_date": ["ê°€ì…", "ë“±ë¡ì¼", "íšŒì›ê°€ì…", "ê°€ì…ì¼", "ê°€ì… ë‚ ì§œ", "ë“±ë¡ì¼ì"],
    "order_id": ["ì£¼ë¬¸ë²ˆí˜¸", "ê±°ë˜ ë²ˆí˜¸", "Order No.", "ì£¼ë¬¸ ID", "ì£¼ë¬¸ ì½”ë“œ"],
    "order_date": ["ì£¼ë¬¸ì¼", "ê²°ì œì¼", "êµ¬ë§¤ ë‚ ì§œ", "êµ¬ë§¤ì¼ì", "ê±°ë˜ì¼ì", "ì£¼ë¬¸ì¼ì"],
    "order_status": ["ì£¼ë¬¸ ìƒíƒœ", "ë°°ì†¡ ìƒíƒœ", "ìƒíƒœ", "ì²˜ë¦¬ìƒíƒœ", "ì£¼ë¬¸ ì§„í–‰", "ì§„í–‰ìƒíƒœ"],
    "total_price": ["ì´ì•¡", "ê²°ì œê¸ˆì•¡", "ì£¼ë¬¸ê¸ˆì•¡", "êµ¬ë§¤ì´ì•¡", "ì´ ê²°ì œ", "ê²°ì œ ê¸ˆì•¡", "í•©ê³„"],
    "payment_method": ["ê²°ì œ ìˆ˜ë‹¨", "ê²°ì œ ë°©ë²•", "ê²°ì œ ë°©ì‹", "Payment", "ì§€ë¶ˆ ë°©ì‹", "ê²°ì œ ìœ í˜•"],
    "shipping_address": ["ì£¼ì†Œ", "ë°°ì†¡ ì£¼ì†Œ", "ìˆ˜ë ¹ì§€", "ë°°ì†¡ì§€", "ë°›ëŠ” ì£¼ì†Œ"],
    "product_id": ["ì œí’ˆ ì½”ë“œ", "ìƒí’ˆë²ˆí˜¸", "ìƒí’ˆ ì½”ë“œ", "ì œí’ˆID", "SKU", "ì œí’ˆë²ˆí˜¸"],
    "product_name": ["ìƒí’ˆëª…", "ì œí’ˆëª…", "ìƒí’ˆ ì´ë¦„", "íŒë§¤ ìƒí’ˆ", "êµ¬ë§¤ìƒí’ˆ"],
    "product_category": ["ì¹´í…Œê³ ë¦¬", "ì œí’ˆ ë¶„ë¥˜", "ë¶„ë¥˜", "ìƒí’ˆì¢…ë¥˜", "ìƒí’ˆ ì¹´í…Œê³ ë¦¬"],
    "product_price": ["ë‹¨ê°€", "ê°œë‹¹ ê°€ê²©", "ìƒí’ˆ ê°€ê²©", "íŒë§¤ê°€", "ê°€ê²©"],
    "quantity": ["ìˆ˜ëŸ‰", "êµ¬ë§¤ ìˆ˜ëŸ‰", "ì£¼ë¬¸ ìˆ˜ëŸ‰", "íŒë§¤ ìˆ˜ëŸ‰", "ìˆ˜ëŸ‰(ê°œ)"],
    "inquiry_id": ["ë¬¸ì˜ë²ˆí˜¸", "ìƒë‹´ë²ˆí˜¸", "ì´ìŠˆë²ˆí˜¸"],
    "inquiry_type": ["ë¬¸ì˜ ìœ í˜•", "ì´ìŠˆ ìœ í˜•", "ë¬¸ì˜ ë¶„ë¥˜", "ë¬¸ì˜ ë‚´ìš©", "ì´ìŠˆ íƒ€ì…"],
    "inquiry_create": ["ë¬¸ì˜ì¼ì", "ìš”ì²­ì¼", "ì ‘ìˆ˜ì¼", "ë¬¸ì˜ ë‚ ì§œ", "ë“±ë¡ì¼ì"],
    "inquiry_finish": ["ì²˜ë¦¬ì¼ì", "ì™„ë£Œì¼", "ë‹µë³€ì¼", "í•´ê²°ì¼"],
    "inquiry_status": ["ì§„í–‰ìƒíƒœ", "ì²˜ë¦¬ ìƒíƒœ", "ì‘ë‹µìƒíƒœ", "ë¬¸ì˜ ìƒíƒœ", "í•´ê²° ì—¬ë¶€"]
}

# ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë”© (ë‹¤êµ­ì–´ í¬í•¨)
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
model.to('cpu')  # ëª…ì‹œì ìœ¼ë¡œ CPUë¡œ ì´ë™

# ë°°ì¹˜ í¬ê¸° ì„¤ì •
BATCH_SIZE = 8

# ì…ë ¥ ë° í‘œì¤€ í•„ë“œ ë²¡í„°í™” (ë°°ì¹˜ ì²˜ë¦¬)
input_vectors = []
for i in range(0, len(input_columns), BATCH_SIZE):
    batch = input_columns[i:i + BATCH_SIZE]
    batch_vectors = model.encode(batch, show_progress_bar=False)
    input_vectors.extend(batch_vectors)

# í‘œì¤€ í•„ë“œ(í•œê¸€ ë¼ë²¨) ë²¡í„°í™”
standard_vectors = []
for i in range(0, len(standard_labels), BATCH_SIZE):
    batch = standard_labels[i:i + BATCH_SIZE]
    batch_vectors = model.encode(batch, show_progress_bar=False)
    standard_vectors.extend(batch_vectors)

# ë§¤í•‘ ìˆ˜í–‰ (ë£° ê¸°ë°˜ ìš°ì„  â†’ AI ë³´ì¡°)
mapping_results = {}

for i, input_col in enumerate(input_columns):
    matched = False
    for field, keywords in rule_based_mapping.items():
        if any(keyword in input_col for keyword in keywords):
            mapping_results[input_col] = (field, 1.0)
            matched = True
            break
    if not matched:
        similarities = cosine_similarity([input_vectors[i]], standard_vectors)[0]
        best_match_idx = np.argmax(similarities)
        predicted_field = standard_fields[best_match_idx]  # ë‚´ë¶€ í•„ë“œë¡œ ì €ì¥
        score = similarities[best_match_idx]
        mapping_results[input_col] = (predicted_field, round(float(score), 4))

# ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Œ í•„ë“œ ë§¤í•‘ ê²°ê³¼:")
print("-" * 40)
for input_col, (predicted, score) in mapping_results.items():
    print(f"{input_col:20} â†’  {predicted:20} (ìœ ì‚¬ë„: {score})")